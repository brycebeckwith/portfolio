{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pages = list(range(5,200,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GBI_TA = []\n",
    "req = requests.get('https://www.tripadvisor.com/Hotel_Review-g43686-d280454-Reviews-Harrah_s_Gulf_Coast-Biloxi_Mississippi.html')\n",
    "soup = BeautifulSoup(req.text, \"lxml\")\n",
    "for post in soup.findAll(attrs={'class':'ratingDate relativeDate'}):\n",
    "    GBI_TA.append(post['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for pos in pages:\n",
    "    req = requests.get('https://www.tripadvisor.com/Hotel_Review-g43686-d280454-Reviews-or%d-Harrah_s_Gulf_Coast-Biloxi_Mississippi.html' % pos)\n",
    "    soup = BeautifulSoup(req.text, \"lxml\")\n",
    "\n",
    "    for post in soup.findAll(attrs={'class':'ratingDate relativeDate'}):\n",
    "        GBI_TA.append(post['title'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Hotel_Reviews = []\n",
    "req = requests.get(\"https://www.tripadvisor.com/Hotel_Review-g43686-d280454-Reviews-Harrah_s_Gulf_Coast-Biloxi_Mississippi.html\" )\n",
    "soup = BeautifulSoup(req.text, \"lxml\")\n",
    "\n",
    "for post in soup.findAll(attrs={'class' : 'partial_entry'}):\n",
    "    Hotel_Reviews.append(post.getText())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for pos in pages:\n",
    "    req = requests.get('https://www.tripadvisor.com/Hotel_Review-g43686-d280454-Reviews-or%d-Harrah_s_Gulf_Coast-Biloxi_Mississippi.html' % pos)\n",
    "    soup = BeautifulSoup(req.text, \"lxml\")\n",
    "\n",
    "    for post in soup.findAll(attrs={'class' : 'partial_entry'}):\n",
    "        Hotel_Reviews.append(post.getText())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(GBI_TA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "370"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([ x for x in Hotel_Reviews if \"Dear\" not in x ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Hotel_Review = [ x for x in Hotel_Reviews if \"Dear\" not in x ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Beau_Rivage_TA = []\n",
    "req = requests.get('https://www.tripadvisor.com/Hotel_Review-g43686-d90557-Reviews-Beau_Rivage_Resort_Casino_Biloxi-Biloxi_Mississippi.html')\n",
    "soup = BeautifulSoup(req.text, \"lxml\")\n",
    "for post in soup.findAll(attrs={'class':'ratingDate relativeDate'}):\n",
    "    Beau_Rivage_TA.append(post['title'])\n",
    "\n",
    "for pos in pages:\n",
    "    req = requests.get('https://www.tripadvisor.com/Hotel_Review-g43686-d90557-Reviews-or%d-Beau_Rivage_Resort_Casino_Biloxi-Biloxi_Mississippi.html' % pos)\n",
    "    soup = BeautifulSoup(req.text, \"lxml\")\n",
    "\n",
    "    for post in soup.findAll(attrs={'class':'ratingDate relativeDate'}):\n",
    "        Beau_Rivage_TA.append(post['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Beau_Rivage_Hotel_Reviews = []\n",
    "req = requests.get('https://www.tripadvisor.com/Hotel_Review-g43686-d90557-Reviews-Beau_Rivage_Resort_Casino_Biloxi-Biloxi_Mississippi.html')\n",
    "soup = BeautifulSoup(req.text, \"lxml\")\n",
    "\n",
    "for post in soup.findAll(attrs={'class' : 'partial_entry'}):\n",
    "    Beau_Rivage_Hotel_Reviews.append(post.getText())\n",
    "\n",
    "for pos in pages:\n",
    "    req = requests.get('https://www.tripadvisor.com/Hotel_Review-g43686-d90557-Reviews-or%d-Beau_Rivage_Resort_Casino_Biloxi-Biloxi_Mississippi.html' % pos)\n",
    "    soup = BeautifulSoup(req.text, \"lxml\")\n",
    "\n",
    "    for post in soup.findAll(attrs={'class' : 'partial_entry'}):\n",
    "        Beau_Rivage_Hotel_Reviews.append(post.getText())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Beau_Rivage_TA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([ x for x in Beau_Rivage_Hotel_Reviews if \"Dear\" not in x ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Beau_Rivage_Hotel_Reviews = [ x for x in Beau_Rivage_Hotel_Reviews if \"Dear\" not in x ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Hard_Rock_TA = []\n",
    "req = requests.get('https://www.tripadvisor.com/Hotel_Review-g43686-d662509-Reviews-Hard_Rock_Hotel_Casino_Biloxi-Biloxi_Mississippi.html')\n",
    "soup = BeautifulSoup(req.text, \"lxml\")\n",
    "for post in soup.findAll(attrs={'class':'ratingDate relativeDate'}):\n",
    "    Hard_Rock_TA.append(post['title'])\n",
    "\n",
    "for pos in pages:\n",
    "    req = requests.get('https://www.tripadvisor.com/Hotel_Review-g43686-d662509-Reviews-or%d-Hard_Rock_Hotel_Casino_Biloxi-Biloxi_Mississippi.html' % pos)\n",
    "    soup = BeautifulSoup(req.text, \"lxml\")\n",
    "\n",
    "    for post in soup.findAll(attrs={'class':'ratingDate relativeDate'}):\n",
    "        Hard_Rock_TA.append(post['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Hard_Rock_Hotel_Reviews = []\n",
    "req = requests.get('https://www.tripadvisor.com/Hotel_Review-g43686-d662509-Reviews-Hard_Rock_Hotel_Casino_Biloxi-Biloxi_Mississippi.html')\n",
    "soup = BeautifulSoup(req.text, \"lxml\")\n",
    "\n",
    "for post in soup.findAll(attrs={'class' : 'partial_entry'}):\n",
    "    Hard_Rock_Hotel_Reviews.append(post.getText())\n",
    "\n",
    "for pos in pages:\n",
    "    req = requests.get('https://www.tripadvisor.com/Hotel_Review-g43686-d662509-Reviews-or%d-Hard_Rock_Hotel_Casino_Biloxi-Biloxi_Mississippi.html' % pos)\n",
    "    soup = BeautifulSoup(req.text, \"lxml\")\n",
    "\n",
    "    for post in soup.findAll(attrs={'class' : 'partial_entry'}):\n",
    "        Hard_Rock_Hotel_Reviews.append(post.getText())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Hard_Rock_TA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([ x for x in Hard_Rock_Hotel_Reviews if \"Dear\" not in x ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Hard_Rock_Hotel_Reviews = [ x for x in Hard_Rock_Hotel_Reviews if \"Dear\" not in x ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Beau_Rivage_Hotel_Reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "IP_TA = []\n",
    "req = requests.get('https://www.tripadvisor.com/Hotel_Review-g43686-d90565-Reviews-IP_Casino_Resort_Spa_Biloxi-Biloxi_Mississippi.html')\n",
    "soup = BeautifulSoup(req.text, \"lxml\")\n",
    "for post in soup.findAll(attrs={'class':'ratingDate relativeDate'}):\n",
    "    IP_TA.append(post['title'])\n",
    "\n",
    "for pos in pages:\n",
    "    req = requests.get('https://www.tripadvisor.com/Hotel_Review-g43686-d90565-Reviews-or%d-IP_Casino_Resort_Spa_Biloxi-Biloxi_Mississippi.html' % pos)\n",
    "    soup = BeautifulSoup(req.text, \"lxml\")\n",
    "\n",
    "    for post in soup.findAll(attrs={'class':'ratingDate relativeDate'}):\n",
    "        IP_TA.append(post['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "IP_Hotel_Reviews = []\n",
    "req = requests.get('https://www.tripadvisor.com/Hotel_Review-g43686-d90565-Reviews-IP_Casino_Resort_Spa_Biloxi-Biloxi_Mississippi.html')\n",
    "soup = BeautifulSoup(req.text, \"lxml\")\n",
    "\n",
    "for post in soup.findAll(attrs={'class' : 'partial_entry'}):\n",
    "    IP_Hotel_Reviews.append(post.getText())\n",
    "\n",
    "for pos in pages:\n",
    "    req = requests.get('https://www.tripadvisor.com/Hotel_Review-g43686-d90565-Reviews-or%d-IP_Casino_Resort_Spa_Biloxi-Biloxi_Mississippi.html' % pos)\n",
    "    soup = BeautifulSoup(req.text, \"lxml\")\n",
    "\n",
    "    for post in soup.findAll(attrs={'class' : 'partial_entry'}):\n",
    "        IP_Hotel_Reviews.append(post.getText())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "215\n"
     ]
    }
   ],
   "source": [
    "print (len(IP_TA))\n",
    "print (len([ x for x in IP_Hotel_Reviews if \"Dear\" not in x ]))\n",
    "IP_Hotel_Reviews = [ x for x in IP_Hotel_Reviews if \"Dear\" not in x ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GN_TA = []\n",
    "req = requests.get('https://www.tripadvisor.com/Hotel_Review-g43686-d96085-Reviews-Golden_Nugget_Biloxi-Biloxi_Mississippi.html')\n",
    "soup = BeautifulSoup(req.text, \"lxml\")\n",
    "for post in soup.findAll(attrs={'class':'ratingDate relativeDate'}):\n",
    "    GN_TA.append(post['title'])\n",
    "\n",
    "for pos in pages:\n",
    "    req = requests.get('https://www.tripadvisor.com/Hotel_Review-g43686-d96085-Reviews-or%d-Golden_Nugget_Biloxi-Biloxi_Mississippi.html' % pos)\n",
    "    soup = BeautifulSoup(req.text, \"lxml\")\n",
    "\n",
    "    for post in soup.findAll(attrs={'class':'ratingDate relativeDate'}):\n",
    "        GN_TA.append(post['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GN_Hotel_Reviews = []\n",
    "req = requests.get('https://www.tripadvisor.com/Hotel_Review-g43686-d96085-Reviews-Golden_Nugget_Biloxi-Biloxi_Mississippi.html')\n",
    "soup = BeautifulSoup(req.text, \"lxml\")\n",
    "\n",
    "for post in soup.findAll(attrs={'class' : 'partial_entry'}):\n",
    "    GN_Hotel_Reviews.append(post.getText())\n",
    "\n",
    "for pos in pages:\n",
    "    req = requests.get('https://www.tripadvisor.com/Hotel_Review-g43686-d96085-Reviews-or%d-Golden_Nugget_Biloxi-Biloxi_Mississippi.html' % pos)\n",
    "    soup = BeautifulSoup(req.text, \"lxml\")\n",
    "\n",
    "    for post in soup.findAll(attrs={'class' : 'partial_entry'}):\n",
    "        GN_Hotel_Reviews.append(post.getText())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "206\n"
     ]
    }
   ],
   "source": [
    "print (len(GN_TA))\n",
    "print (len([ x for x in GN_Hotel_Reviews if \"Dear\" not in x ]))\n",
    "GN_Hotel_Reviews = [ x for x in GN_Hotel_Reviews if \"Dear\" not in x ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PC_TA = []\n",
    "req = requests.get('https://www.tripadvisor.com/Hotel_Review-g43686-d249417-Reviews-Palace_Casino_Resort-Biloxi_Mississippi.html')\n",
    "soup = BeautifulSoup(req.text, \"lxml\")\n",
    "for post in soup.findAll(attrs={'class':'ratingDate relativeDate'}):\n",
    "    PC_TA.append(post['title'])\n",
    "\n",
    "for pos in pages:\n",
    "    req = requests.get('https://www.tripadvisor.com/Hotel_Review-g43686-d249417-Reviews-or%d-Palace_Casino_Resort-Biloxi_Mississippi.html' % pos)\n",
    "    soup = BeautifulSoup(req.text, \"lxml\")\n",
    "\n",
    "    for post in soup.findAll(attrs={'class':'ratingDate relativeDate'}):\n",
    "        PC_TA.append(post['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PC_Hotel_Reviews = []\n",
    "req = requests.get('https://www.tripadvisor.com/Hotel_Review-g43686-d249417-Reviews-Palace_Casino_Resort-Biloxi_Mississippi.html')\n",
    "soup = BeautifulSoup(req.text, \"lxml\")\n",
    "\n",
    "for post in soup.findAll(attrs={'class' : 'partial_entry'}):\n",
    "    PC_Hotel_Reviews.append(post.getText())\n",
    "\n",
    "for pos in pages:\n",
    "    req = requests.get('https://www.tripadvisor.com/Hotel_Review-g43686-d249417-Reviews-or%d-Palace_Casino_Resort-Biloxi_Mississippi.html' % pos)\n",
    "    soup = BeautifulSoup(req.text, \"lxml\")\n",
    "\n",
    "    for post in soup.findAll(attrs={'class' : 'partial_entry'}):\n",
    "        PC_Hotel_Reviews.append(post.getText())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "245\n"
     ]
    }
   ],
   "source": [
    "print (len(PC_TA))\n",
    "print (len([ x for x in PC_Hotel_Reviews if \"Dear\" not in x ]))\n",
    "PC_Hotel_Reviews = [ x for x in PC_Hotel_Reviews if \"Dear\" not in x ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GBI = pd.DataFrame({'review':Hotel_Review[:260],'date': GBI_TA, 'post':'GBI' })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BR = pd.DataFrame({'review':Beau_Rivage_Hotel_Reviews[:200],'date': Beau_Rivage_TA, 'post':'Beau Rivage' })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HR = pd.DataFrame({'review':Hard_Rock_Hotel_Reviews[:200],'date': Hard_Rock_TA, 'post':'Hard Rock' })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IP = pd.DataFrame({'review':IP_Hotel_Reviews[:200],'date': IP_TA, 'post':'IP' })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GN = pd.DataFrame({'review':GN_Hotel_Reviews[:200],'date': GN_TA, 'post':'Golden Nugget' })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PC = pd.DataFrame({'review':PC_Hotel_Reviews[:200],'date': PC_TA, 'post':'Palace Casino' })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TA = pd.concat([GBI, BR, HR, IP, GN, PC])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TA = TA.apply(lambda x: x.astype(str).str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "import nltk\n",
    "TA['sentiment'] = TA['review'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "TA['nouns'] = TA['review'].apply(lambda x: TextBlob(x).noun_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>post</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beau rivage</th>\n",
       "      <td>0.339657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gbi</th>\n",
       "      <td>0.326636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>golden nugget</th>\n",
       "      <td>0.308463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hard rock</th>\n",
       "      <td>0.306629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ip</th>\n",
       "      <td>0.308463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>palace casino</th>\n",
       "      <td>0.348496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               sentiment\n",
       "post                    \n",
       "beau rivage     0.339657\n",
       "gbi             0.326636\n",
       "golden nugget   0.308463\n",
       "hard rock       0.306629\n",
       "ip              0.308463\n",
       "palace casino   0.348496"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TA.groupby(['post']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "# TA['NBA'] = TA['review'].apply(lambda x: TextBlob(x, analyzer=NaiveBayesAnalyzer()))\n",
    "# TA['classification'] = TA['review'].apply(lambda x : x.sentiment.classification)\n",
    "# TA['p_pos'] = TA['NBA'].apply(lambda x : x.sentiment.p_pos)\n",
    "# TA['p_neg'] = TA['NBA'].apply(lambda x : x.sentiment.p_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy \n",
    "import csv\n",
    "\n",
    "consumer_token = \"PJcj3bbtl4EiwdDbRt8Ys1dvh\"\n",
    "consumer_secret = \"HK2fhhmfyRctAP74UmnxL4disTVQrpN9k1PpCvgkfekG21kx3i\"\n",
    "access_key = \"1872558674-XTX2hS59qFwNqlCUTlE3abJ8YqqKMNocxfz44AK\"\n",
    "access_secret = \"PZ6RG1cxo6fxONGGpeSodYLDiczGIgmxAgDsU0WRM49q8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "auth = tweepy.AppAuthHandler(consumer_token, consumer_secret)\n",
    "auth.secure = True\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import jsonpickle\n",
    "\n",
    "def tweepy_pull(username):\n",
    "\n",
    "    searchQuery = username\n",
    "    retweet_filter='-filter:retweets'\n",
    "    q=searchQuery+retweet_filter\n",
    "    tweetsPerQry = 1000\n",
    "    fName = '%s_tweets.csv' % searchQuery\n",
    "    sinceId = None\n",
    "    maxTweets = 10000\n",
    "    max_id = -1\n",
    "    tweetCount = 0\n",
    "    print(\"Downloading max {0} tweets\".format(maxTweets))\n",
    "    with open(fName, 'w') as f:\n",
    "        while tweetCount < maxTweets:\n",
    "            try:\n",
    "                if (max_id <= 0):\n",
    "                    if (not sinceId):\n",
    "                        new_tweets = api.search(q=searchQuery, count=tweetsPerQry)\n",
    "                    else:\n",
    "                        new_tweets = api.search(q=searchQuery, count=tweetsPerQry,\n",
    "                                                since_id=sinceId)\n",
    "                else:\n",
    "                    if (not sinceId):\n",
    "                        new_tweets = api.search(q=searchQuery, count=tweetsPerQry,\n",
    "                                                max_id=str(max_id - 1))\n",
    "                    else:\n",
    "                        new_tweets = api.search(q=searchQuery, count=tweetsPerQry,\n",
    "                                                max_id=str(max_id - 1),\n",
    "                                                since_id=sinceId)\n",
    "                if not new_tweets:\n",
    "                    print(\"No more tweets found\")\n",
    "                    break\n",
    "\n",
    "                for tweet in new_tweets:\n",
    "                    f.write(jsonpickle.encode(tweet._json['text'], unpicklable=False) +\n",
    "                            '\\n')\n",
    "                tweetCount += len(new_tweets)\n",
    "                print(\"Downloaded {0} tweets\".format(tweetCount))\n",
    "                max_id = new_tweets[-1].id\n",
    "            except tweepy.TweepError as e:\n",
    "                # Just exit if any error\n",
    "                print(\"some error : \" + str(e))\n",
    "                break\n",
    "\n",
    "    print (\"Downloaded {0} tweets, Saved to {1}\".format(tweetCount, fName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading max 10000 tweets\n",
      "Downloaded 17 tweets\n",
      "No more tweets found\n",
      "Downloaded 17 tweets, Saved to HarrahsGC_tweets.csv\n"
     ]
    }
   ],
   "source": [
    "tweepy_pull('HarrahsGC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading max 10000 tweets\n",
      "Downloaded 97 tweets\n",
      "Downloaded 98 tweets\n",
      "No more tweets found\n",
      "Downloaded 98 tweets, Saved to BeauBiloxi_tweets.csv\n"
     ]
    }
   ],
   "source": [
    "tweepy_pull('BeauBiloxi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading max 10000 tweets\n",
      "Downloaded 25 tweets\n",
      "No more tweets found\n",
      "Downloaded 25 tweets, Saved to HRHCBiloxi_tweets.csv\n"
     ]
    }
   ],
   "source": [
    "tweepy_pull('HRHCBiloxi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading max 10000 tweets\n",
      "Downloaded 19 tweets\n",
      "No more tweets found\n",
      "Downloaded 19 tweets, Saved to GoldenNuggetBX_tweets.csv\n"
     ]
    }
   ],
   "source": [
    "tweepy_pull('GoldenNuggetBX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GN = pd.read_csv('GoldenNuggetBX_tweets.csv', header=None)\n",
    "HR = pd.read_csv('HRHCBiloxi_tweets.csv', header=None)\n",
    "BR = pd.read_csv('BeauBiloxi_tweets.csv', header=None)\n",
    "GBI = pd.read_csv('HarrahsGC_tweets.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GN['Loc'] = 'GN'\n",
    "HR['Loc'] = 'HR'\n",
    "BR['Loc'] = 'BR'\n",
    "GBI['Loc'] = 'GBI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TA = pd.concat([GBI, BR, HR, GN])\n",
    "TA = TA.apply(lambda x: x.astype(str).str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TA.columns = ['tweet','post']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "import nltk\n",
    "TA['sentiment'] = TA['tweet'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "TA['nouns'] = TA['tweet'].apply(lambda x: TextBlob(x).noun_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>post</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>br</th>\n",
       "      <td>0.267361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gbi</th>\n",
       "      <td>0.058946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gn</th>\n",
       "      <td>0.282237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hr</th>\n",
       "      <td>0.090916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment\n",
       "post           \n",
       "br     0.267361\n",
       "gbi    0.058946\n",
       "gn     0.282237\n",
       "hr     0.090916"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TA.groupby(['post']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python35]",
   "language": "python",
   "name": "conda-env-python35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
