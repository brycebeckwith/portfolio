{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Websites:\n",
    "# 1. https://www.rent.com/california/los-angeles-apartments/axis-4-100064358\n",
    "# Scrape data of each available unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Key Data Features:\n",
    "# - Address and unit number\n",
    "# - Sq ft\n",
    "# - Type (studio, home, apartment)\n",
    "# - Beds\n",
    "# - Baths\n",
    "# - Date available\n",
    "# - Asking rent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /Users/bryceeb/anaconda/envs/python35/lib/python3.5/site-packages\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 20.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /Users/bryceeb/anaconda/envs/python35/lib/python3.5/site-packages\n",
      "Requirement already satisfied: urllib3 in /Users/bryceeb/anaconda/envs/python35/lib/python3.5/site-packages (from selenium)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 20.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys  \n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "from random import randint\n",
    "pd.set_option('display.max_rows', 500)\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Install homebrew on mac\n",
    "# Follow Instructions from https://medium.com/dropout-analytics/selenium-and-geckodriver-on-mac-b411dbfe61bc\n",
    "# Install geckodriver via homebrew\n",
    "# Copy Paste \"/usr/local/bin/geckodriver\" file path. This should remain the same, but in case it does not you \n",
    "# you will need to replace every executable_path variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinkedIn Crawler_3262020.ipynb        rent_com_get_apt_links_for_city.ipynb\r\n",
      "geckodriver.log                       \u001b[34mwebdriver\u001b[m\u001b[m\r\n",
      "rent_com_get_apartment_details.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "#confirm geckodriver is in list below\n",
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bryceeb/anaconda/envs/python35/lib/python3.5/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 184 of the file /Users/bryceeb/anaconda/envs/python35/lib/python3.5/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "options = webdriver.FirefoxOptions()\n",
    "options.add_argument(\"start-maximized\")\n",
    "options.add_argument('disable-infobars')\n",
    "\n",
    "browser = webdriver.Firefox(options=options, \n",
    "                           executable_path='/usr/local/bin/geckodriver')\n",
    "\n",
    "city = 'los-angeles-apartments'.replace('-','_')\n",
    "\n",
    "browser.get('https://www.rent.com/california/los-angeles-apartments')\n",
    "result=BeautifulSoup(browser.page_source)\n",
    "\n",
    "#getting the first page of apartment link results and saving to apartment_link dataframe variable\n",
    "apartment_link = pd.DataFrame()\n",
    "for link in result.findAll('a', {'class': '_1Fv8S _3DZdx'}):\n",
    "    try:\n",
    "        apartment_link = apartment_link.append([\"https://www.rent.com/\" + link['href']])\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "#finding the max amount of pages the geo/dma/msa has\n",
    "properties_found = result.findAll('div', {'class': '_1Uvv-'})[0]\n",
    "properties_found_text = properties_found.text\n",
    "total_properties = int(re.findall(r'\\d+', properties_found_text)[0])\n",
    "max_pages = round(total_properties / len(apartment_link),0)\n",
    "\n",
    "#Saving next page links to next_page_directory dataframe variable\n",
    "next_page_directory = pd.DataFrame()\n",
    "for page_number in range(2, int(max_pages)):\n",
    "    next_page_directory = next_page_directory.append(['https://www.rent.com/california/los-angeles-apartments?page=%s' %page_number])\n",
    "next_page_directory.columns = ['page_url']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bryceeb/anaconda/envs/python35/lib/python3.5/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 184 of the file /Users/bryceeb/anaconda/envs/python35/lib/python3.5/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "for i, row in next_page_directory.iterrows():\n",
    "    browser = webdriver.Firefox(options=options, \n",
    "                           executable_path='/usr/local/bin/geckodriver')\n",
    "\n",
    "    browser.get(row['page_url'])\n",
    "    result=BeautifulSoup(browser.page_source)\n",
    "\n",
    "    #getting the first page of apartment link results and saving to apartment_link dataframe variable\n",
    "\n",
    "    for link in result.findAll('a', {'class': '_1Fv8S _3DZdx'}):\n",
    "        try:\n",
    "            apartment_link = apartment_link.append([\"https://www.rent.com/\" + link['href']])\n",
    "        except KeyError:\n",
    "            pass\n",
    "        \n",
    "    browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "apartment_link = apartment_link.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "city = 'los-angeles-apartments'.replace('-','_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "apartment_link.to_csv('%s_urls.csv' % city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python35]",
   "language": "python",
   "name": "conda-env-python35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
