{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Websites:\n",
    "# 1. https://www.rent.com/california/los-angeles-apartments/axis-4-100064358\n",
    "# Scrape data of each available unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Key Data Features:\n",
    "# - Address and unit number\n",
    "# - Sq ft\n",
    "# - Type (studio, home, apartment)\n",
    "# - Beds\n",
    "# - Baths\n",
    "# - Date available\n",
    "# - Asking rent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fuzzywuzzy in /Users/bryceeb/anaconda/envs/python35/lib/python3.5/site-packages\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 20.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install fuzzywuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /Users/bryceeb/anaconda/envs/python35/lib/python3.5/site-packages\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 20.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /Users/bryceeb/anaconda/envs/python35/lib/python3.5/site-packages\n",
      "Requirement already satisfied: urllib3 in /Users/bryceeb/anaconda/envs/python35/lib/python3.5/site-packages (from selenium)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 20.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys  \n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "from random import randint\n",
    "pd.set_option('display.max_rows', 500)\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Install homebrew on mac\n",
    "# Follow Instructions from https://medium.com/dropout-analytics/selenium-and-geckodriver-on-mac-b411dbfe61bc\n",
    "# Install geckodriver via homebrew\n",
    "# Copy Paste \"/usr/local/bin/geckodriver\" file path. This should remain the same, but in case it does not you \n",
    "# you will need to replace every executable_path variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinkedIn Crawler_3262020.ipynb        rent_com_get_apartment_details.ipynb\r\n",
      "geckodriver.log                       rent_com_get_apt_links_for_city.ipynb\r\n",
      "los_angeles_apartments_details.csv    \u001b[34mwebdriver\u001b[m\u001b[m\r\n",
      "los_angeles_apartments_urls.csv\r\n"
     ]
    }
   ],
   "source": [
    "#confirm geckodriver is in list below\n",
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://www.rent.com//california/burbank-apart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>https://www.rent.com//california/los-angeles-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>https://www.rent.com//california/hollywood-apa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>https://www.rent.com//california/glendale-apar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>https://www.rent.com//california/burbank-apart...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                                  0\n",
       "0           0  https://www.rent.com//california/burbank-apart...\n",
       "1           0  https://www.rent.com//california/los-angeles-a...\n",
       "2           0  https://www.rent.com//california/hollywood-apa...\n",
       "3           0  https://www.rent.com//california/glendale-apar...\n",
       "4           0  https://www.rent.com//california/burbank-apart..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apartment_df = pd.read_csv('los_angeles_apartments_urls.csv')\n",
    "apartment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "apartment_info_already_scraped = pd.read_csv('los_angeles_apartments_details.csv')\n",
    "apartment_info_already_scraped = apartment_info_already_scraped['url_link'].unique()\n",
    "links_not_yet_scraped = (set(apartment_df['0'].tolist()) - set(apartment_info_already_scraped))\n",
    "all_links = apartment_df['0'].tolist()\n",
    "links_not_yet_scraped = list(links_not_yet_scraped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links_not_yet_scraped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4676"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(apartment_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_of_apartment_urls = links_not_yet_scraped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bryceeb/anaconda/envs/python35/lib/python3.5/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 184 of the file /Users/bryceeb/anaconda/envs/python35/lib/python3.5/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "for page_url in list_of_apartment_urls:\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "    options = webdriver.FirefoxOptions()\n",
    "    options.add_argument(\"start-maximized\")\n",
    "    options.add_argument('disable-infobars')\n",
    "\n",
    "    page_url = page_url\n",
    "\n",
    "    browser = webdriver.Firefox(options=options, \n",
    "                               executable_path='/usr/local/bin/geckodriver')\n",
    "\n",
    "    browser.get(page_url)\n",
    "    result=BeautifulSoup(browser.page_source)\n",
    "\n",
    "    description = result.findAll('td', {'data-tid': 'pdpfloorplan-displayText'})\n",
    "    price = result.findAll('td', {'data-tid': 'pdpfloorplan-price'})\n",
    "    bedbaths = result.findAll('td', {'data-tid': 'pdpfloorplan-bedbaths'})\n",
    "    sqft = result.findAll('td', {'data-tid': 'pdpfloorplan-sqft'})\n",
    "    available = result.findAll('td', {'data-tid': 'pdpfloorplans-unavailable'})\n",
    "\n",
    "    browser.quit()\n",
    "\n",
    "    description_text = []\n",
    "    for text_ in description:\n",
    "        description_text.append(text_.text)\n",
    "\n",
    "    price_text = []\n",
    "    for text_ in price:\n",
    "        price_text.append(text_.text)\n",
    "\n",
    "    bedbaths_text = []\n",
    "    for text_ in bedbaths:\n",
    "        bedbaths_text.append(text_.text)\n",
    "\n",
    "    sqft_text = []\n",
    "    for text_ in sqft:\n",
    "        sqft_text.append(text_.text)\n",
    "\n",
    "    available_text = []\n",
    "    for text_ in available:\n",
    "        available_text.append(text_.text)\n",
    "\n",
    "    details = pd.DataFrame([description_text,price_text,bedbaths_text,sqft_text,available_text]).T\n",
    "    details.columns = ['description', 'price', 'bedbaths','sqft','available']\n",
    "    \n",
    "    if len(details) == 0:\n",
    "        details = pd.DataFrame([['','','','','']])\n",
    "        details.columns = ['description', 'price', 'bedbaths','sqft','available']\n",
    "    else:\n",
    "        details = details\n",
    "\n",
    "    try:\n",
    "        details['bedrooms_extract'] = details['bedbaths'].str.extract(r'((Studio)|((\\d+) Bed))', expand=False)[0]\n",
    "    except:\n",
    "        details['bedrooms_extract'] = \"na\"\n",
    "        \n",
    "    try:\n",
    "        details['bathrooms_extract'] = details['bedbaths'].str.extract(r'(((\\d+) Bath)|((\\d+) Baths))', expand=False)[0]\n",
    "    except:\n",
    "        details['bathrooms_extract'] = \"na\"\n",
    "    \n",
    "    try:\n",
    "        details['price_extract'] = details['price'].str.extract(r'([0-9]+(,[0-9]+)+)', expand=False)[0]\n",
    "    except:\n",
    "        details['price_extract'] = \"na\"\n",
    "        \n",
    "    try:\n",
    "        details['sqft_extract'] = details['sqft'].str.extract(r'([0-9]+)', expand=False)\n",
    "    except:\n",
    "        details['sqft_extract'] = \"na\"\n",
    "\n",
    "    try:\n",
    "        address = result.findAll('div', {'data-tid': 'pdpKeyInfo_citystatezip'})[0]\n",
    "        address = address.text\n",
    "    except:\n",
    "        address = \"na\"\n",
    "    \n",
    "    \n",
    "    try: \n",
    "        neighborhood = result.findAll('div', {'data-tid': 'pdpKeyInfo_neighborhood'})[0]\n",
    "        neighborhood = neighborhood.text\n",
    "    except:\n",
    "        neighborhood = \"na\"\n",
    "\n",
    "    details['address'] = address\n",
    "    details['neighborhood'] = neighborhood\n",
    "    details['url_link'] = page_url\n",
    "    details['scrape_date'] = pd.to_datetime('today')\n",
    "    \n",
    "    city = 'los-angeles-apartments'.replace('-','_')\n",
    "\n",
    "    if all_links.index(page_url) == 0:\n",
    "        details.to_csv('%s_details.csv' % city)\n",
    "    else: \n",
    "        with open('%s_details.csv' % city, 'a') as f:\n",
    "            details.to_csv(f, header=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data.reset_index(inplace=True)\n",
    "# data_dict = data.to_dict(\"records\")\n",
    "# company.insert_one({\"index\":\"Sensex\",\"data\":data_dict})"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
